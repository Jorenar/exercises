{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 14:44:55.242429: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-03 14:44:55.242463: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"Grafika/transfer_learning.png\" width=\"550\">\n",
    "\n",
    "**Transfer learning** (transfer \"wiedzy\") - wykorzystanie nauczonych przez kogoś sieci do naszego problemu. Możliwe dzięki temu, że cechy wykrywane przez sieci w głębokich warstwach mogą być uniwersalne i przydatne w różnych problemach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import vgg16\n",
    "base_model = vgg16.VGG16(weights='imagenet',include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 299, 299, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 149, 149, 32  864         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 149, 149, 32  96         ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 149, 149, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 147, 147, 32  9216        ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 147, 147, 32  96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 147, 147, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 147, 147, 64  18432       ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 147, 147, 64  192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 147, 147, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 73, 73, 64)   0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 73, 73, 80)   5120        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 73, 73, 80)  240         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 73, 73, 80)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 71, 71, 192)  138240      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 71, 71, 192)  576        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 71, 71, 192)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0          ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 35, 35, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 35, 35, 96)   55296       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 35, 35, 48)  144         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 35, 35, 96)  288         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 35, 35, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 35, 35, 96)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 35, 35, 192)  0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 35, 35, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 35, 35, 64)   76800       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 35, 35, 32)   6144        ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 35, 35, 64)  192         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 35, 35, 96)  288         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 35, 35, 32)  96          ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 35, 35, 64)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 35, 35, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " mixed0 (Concatenate)           (None, 35, 35, 256)  0           ['activation_5[0][0]',           \n",
      "                                                                  'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 35, 35, 64)  192         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 35, 35, 48)   12288       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 35, 35, 48)  144         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 35, 35, 96)  288         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (AveragePo  (None, 35, 35, 256)  0          ['mixed0[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 35, 35, 64)   16384       ['mixed0[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 35, 35, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 35, 35, 64)  192         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 35, 35, 64)  192         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 35, 35, 96)  288         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 35, 35, 64)  192         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " mixed1 (Concatenate)           (None, 35, 35, 288)  0           ['activation_12[0][0]',          \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]',          \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 35, 35, 64)  192         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 35, 35, 48)   13824       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 35, 35, 48)  144         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 35, 35, 96)  288         ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 35, 35, 48)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 35, 35, 288)  0          ['mixed1[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 35, 35, 64)   76800       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 35, 35, 96)   82944       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 35, 35, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 35, 35, 64)  192         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 35, 35, 64)  192         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 35, 35, 96)  288         ['conv2d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 35, 35, 64)  192         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " mixed2 (Concatenate)           (None, 35, 35, 288)  0           ['activation_19[0][0]',          \n",
      "                                                                  'activation_21[0][0]',          \n",
      "                                                                  'activation_24[0][0]',          \n",
      "                                                                  'activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 35, 35, 64)   18432       ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 35, 35, 64)  192         ['conv2d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 35, 35, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 35, 35, 96)   55296       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 35, 35, 96)  288         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 35, 35, 96)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 17, 17, 384)  995328      ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 17, 17, 96)   82944       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 17, 17, 384)  1152       ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 17, 17, 96)  288         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 17, 17, 384)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 17, 17, 96)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0          ['mixed2[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed3 (Concatenate)           (None, 17, 17, 768)  0           ['activation_26[0][0]',          \n",
      "                                                                  'activation_29[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 17, 17, 128)  384        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 17, 17, 128)  384        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 17, 17, 128)  98304       ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 17, 17, 128)  384        ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 17, 17, 128)  384        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 17, 17, 128)  114688      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 17, 17, 128)  384        ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 17, 17, 128)  384        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 17, 17, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 17, 17, 768)  0          ['mixed3[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 17, 17, 192)  172032      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 17, 17, 192)  576        ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 17, 17, 192)  576        ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 17, 17, 192)  576        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 17, 17, 192)  576        ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " mixed4 (Concatenate)           (None, 17, 17, 768)  0           ['activation_30[0][0]',          \n",
      "                                                                  'activation_33[0][0]',          \n",
      "                                                                  'activation_38[0][0]',          \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 17, 17, 160)  480        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 17, 17, 160)  480        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 17, 17, 160)  480        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 17, 17, 160)  480        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 17, 17, 160)  480        ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 17, 17, 160)  480        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_4 (AveragePo  (None, 17, 17, 768)  0          ['mixed4[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 17, 17, 192)  576        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 17, 17, 192)  576        ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 17, 17, 192)  576        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 17, 17, 192)  576        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " mixed5 (Concatenate)           (None, 17, 17, 768)  0           ['activation_40[0][0]',          \n",
      "                                                                  'activation_43[0][0]',          \n",
      "                                                                  'activation_48[0][0]',          \n",
      "                                                                  'activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 17, 17, 160)  480        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 17, 17, 160)  480        ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 17, 17, 160)  122880      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 17, 17, 160)  480        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 17, 17, 160)  480        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 17, 17, 160)  179200      ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 17, 17, 160)  480        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 17, 17, 160)  480        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 17, 17, 160)  0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 17, 17, 768)  0          ['mixed5[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed5[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 17, 17, 192)  215040      ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 17, 17, 192)  576        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 17, 17, 192)  576        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 17, 17, 192)  576        ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 17, 17, 192)  576        ['conv2d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " mixed6 (Concatenate)           (None, 17, 17, 768)  0           ['activation_50[0][0]',          \n",
      "                                                                  'activation_53[0][0]',          \n",
      "                                                                  'activation_58[0][0]',          \n",
      "                                                                  'activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 17, 17, 192)  576        ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 17, 17, 192)  576        ['conv2d_65[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 17, 17, 192)  576        ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 17, 17, 192)  576        ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 17, 17, 192)  576        ['conv2d_62[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 17, 17, 192)  576        ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d_6 (AveragePo  (None, 17, 17, 768)  0          ['mixed6[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed6[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 17, 17, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 17, 17, 192)  576        ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 17, 17, 192)  576        ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 17, 17, 192)  576        ['conv2d_68[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 17, 17, 192)  576        ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " mixed7 (Concatenate)           (None, 17, 17, 768)  0           ['activation_60[0][0]',          \n",
      "                                                                  'activation_63[0][0]',          \n",
      "                                                                  'activation_68[0][0]',          \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 17, 17, 192)  576        ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 17, 17, 192)  576        ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 17, 17, 192)  147456      ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 17, 17, 192)  258048      ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 17, 17, 192)  576        ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 17, 17, 192)  576        ['conv2d_74[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 17, 17, 192)  0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 320)    552960      ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 8, 8, 192)    331776      ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 8, 8, 320)   960         ['conv2d_71[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 8, 8, 192)   576         ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)   0           ['mixed7[0][0]']                 \n",
      "                                                                                                  \n",
      " mixed8 (Concatenate)           (None, 8, 8, 1280)   0           ['activation_71[0][0]',          \n",
      "                                                                  'activation_75[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 8, 8, 448)    573440      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_80[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 8, 8, 384)    491520      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_77[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_7 (AveragePo  (None, 8, 8, 1280)  0           ['mixed8[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 8, 8, 320)    409600      ['mixed8[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_83[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 8, 8, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 8, 8, 320)   960         ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 8, 8, 192)   576         ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_0 (Concatenate)         (None, 8, 8, 768)    0           ['activation_78[0][0]',          \n",
      "                                                                  'activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 8, 768)    0           ['activation_82[0][0]',          \n",
      "                                                                  'activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9 (Concatenate)           (None, 8, 8, 2048)   0           ['activation_76[0][0]',          \n",
      "                                                                  'mixed9_0[0][0]',               \n",
      "                                                                  'concatenate[0][0]',            \n",
      "                                                                  'activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 8, 8, 448)    917504      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 8, 8, 448)   1344        ['conv2d_89[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 8, 8, 448)    0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 8, 8, 384)    786432      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 8, 8, 384)    1548288     ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_86[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 8, 8, 384)    442368      ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " average_pooling2d_8 (AveragePo  (None, 8, 8, 2048)  0           ['mixed9[0][0]']                 \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 8, 8, 320)    655360      ['mixed9[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 8, 8, 384)   1152        ['conv2d_92[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 8, 8, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 8, 8, 320)   960         ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 8, 8, 384)    0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 8, 8, 192)   576         ['conv2d_93[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 8, 8, 320)    0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " mixed9_1 (Concatenate)         (None, 8, 8, 768)    0           ['activation_87[0][0]',          \n",
      "                                                                  'activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 8, 8, 768)    0           ['activation_91[0][0]',          \n",
      "                                                                  'activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 8, 8, 192)    0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " mixed10 (Concatenate)          (None, 8, 8, 2048)   0           ['activation_85[0][0]',          \n",
      "                                                                  'mixed9_1[0][0]',               \n",
      "                                                                  'concatenate_1[0][0]',          \n",
      "                                                                  'activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['mixed10[0][0]']                \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 1000)         2049000     ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,851,784\n",
      "Trainable params: 23,817,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "inc = InceptionV3()\n",
    "inc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Trzeba nadać wymiar wejści anaszej sieci\n",
    "```python\n",
    "h,w = 150, 150\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = 150, 150\n",
    "model = vgg16.VGG16(weights='imagenet',include_top=False,input_shape=(h,w,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad \n",
    "Zbudujmy siec z \n",
    "* VGG16 dla wejścia h,w = 150, 150\n",
    "* Flatten\n",
    "* Dense\n",
    "* Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 1)                 2097665   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "h,w = 150, 150\n",
    "model = vgg16.VGG16(weights='imagenet',include_top=False,input_shape=(h,w,3))\n",
    "\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_transfer = Sequential()\n",
    "model_transfer.add(model)\n",
    "model_transfer.add(top_model)\n",
    "\n",
    "model_transfer.layers[0].trainable = False\n",
    "\n",
    "model_transfer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2097408   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,097,665\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "top_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Naucz model \n",
    " \n",
    "* użyj Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "model_transfer.compile(loss='binary_crossentropy',optimizer=\"sgd\",metrics=['accuracy'])\n",
    "\n",
    "train_data_dir = './Dane/data/train'\n",
    "validation_data_dir = './Dane/data/validation'\n",
    "nb_validation_samples = 200\n",
    "nb_train_samples = 50\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2,\n",
    "                                   rotation_range=45, \n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, \n",
    "                                                    target_size=(h, w), \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size=(h, w), \n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_validation_samples//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p1\\AppData\\Local\\Temp\\ipykernel_2312\\1633517616.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_transfer.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 1.1795 - accuracy: 0.4600WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "10/10 [==============================] - 6s 527ms/step - loss: 1.1795 - accuracy: 0.4600 - val_loss: 0.6506 - val_accuracy: 0.6000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6852 - accuracy: 0.6100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.6852 - accuracy: 0.6100\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7291 - accuracy: 0.5200WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.7291 - accuracy: 0.5200\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6985 - accuracy: 0.5700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 405ms/step - loss: 0.6985 - accuracy: 0.5700\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6245 - accuracy: 0.6700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.6245 - accuracy: 0.6700\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.7300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 401ms/step - loss: 0.5763 - accuracy: 0.7300\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6199 - accuracy: 0.6600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.6199 - accuracy: 0.6600\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5033 - accuracy: 0.7900WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 0.5033 - accuracy: 0.7900\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.7200WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.5345 - accuracy: 0.7200\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5537 - accuracy: 0.6800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.5537 - accuracy: 0.6800\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6099 - accuracy: 0.6600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.6099 - accuracy: 0.6600\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4649 - accuracy: 0.8100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.4649 - accuracy: 0.8100\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.8000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 379ms/step - loss: 0.4465 - accuracy: 0.8000\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.7000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.5853 - accuracy: 0.7000\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4047 - accuracy: 0.8500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.4047 - accuracy: 0.8500\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.7000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 0.6452 - accuracy: 0.7000\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.6019 - accuracy: 0.7000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 366ms/step - loss: 0.6019 - accuracy: 0.7000\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4728 - accuracy: 0.7400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.4728 - accuracy: 0.7400\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.7600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.4983 - accuracy: 0.7600\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.7400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.4802 - accuracy: 0.7400\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.7100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 0.5275 - accuracy: 0.7100\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.7700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.4551 - accuracy: 0.7700\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4038 - accuracy: 0.8100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 0.4038 - accuracy: 0.8100\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3891 - accuracy: 0.8300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.3891 - accuracy: 0.8300\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.7900WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.4716 - accuracy: 0.7900\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5615 - accuracy: 0.7500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.5615 - accuracy: 0.7500\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.8700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.3417 - accuracy: 0.8700\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.8400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.3849 - accuracy: 0.8400\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.8400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.4094 - accuracy: 0.8400\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.7500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 0.5094 - accuracy: 0.7500\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4699 - accuracy: 0.7600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 366ms/step - loss: 0.4699 - accuracy: 0.7600\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4311 - accuracy: 0.7800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.4311 - accuracy: 0.7800\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.7600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 0.4743 - accuracy: 0.7600\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.8800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 366ms/step - loss: 0.3367 - accuracy: 0.8800\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.8900WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.3285 - accuracy: 0.8900\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3849 - accuracy: 0.7900WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 0.3849 - accuracy: 0.7900\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.7000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 0.5602 - accuracy: 0.7000\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.8600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 0.3262 - accuracy: 0.8600\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.8000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.3816 - accuracy: 0.8000\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3714 - accuracy: 0.8000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 0.3714 - accuracy: 0.8000\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.8100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.4528 - accuracy: 0.8100\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4197 - accuracy: 0.8300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.4197 - accuracy: 0.8300\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.8000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 366ms/step - loss: 0.3914 - accuracy: 0.8000\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3869 - accuracy: 0.7900WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.3869 - accuracy: 0.7900\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3170 - accuracy: 0.8800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.3170 - accuracy: 0.8800\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.8800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 368ms/step - loss: 0.3106 - accuracy: 0.8800\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.8700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 0.3093 - accuracy: 0.8700\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3534 - accuracy: 0.8600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.3534 - accuracy: 0.8600\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2797 - accuracy: 0.9000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.2797 - accuracy: 0.9000\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.3301 - accuracy: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16c07b27850>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_tr_ag = History()\n",
    "early_stopping = EarlyStopping(patience=3,monitor=\"val_loss\")\n",
    "model_transfer.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs, \n",
    "                    validation_data=validation_generator, validation_steps=10, callbacks=[early_stopping, history_tr_ag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_tr_ag.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_tr_ag.history['val_accuracy'], label = \"test Adam\")\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Wykonaj zadania na większym zbiorze danych.\n",
    "\n",
    "https://www.microsoft.com/en-us/download/details.aspx?id=54765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 10 images belonging to 2 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p1\\AppData\\Local\\Temp\\ipykernel_2312\\92633756.py:32: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model_transfer.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.8000WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "10/10 [==============================] - 5s 464ms/step - loss: 0.4597 - accuracy: 0.8000 - val_loss: 0.2684 - val_accuracy: 0.9000\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3537 - accuracy: 0.8400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 369ms/step - loss: 0.3537 - accuracy: 0.8400\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.7825 - accuracy: 0.7100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 367ms/step - loss: 0.7825 - accuracy: 0.7100\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3989 - accuracy: 0.8000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 0.3989 - accuracy: 0.8000\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5285 - accuracy: 0.7100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.5285 - accuracy: 0.7100\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4022 - accuracy: 0.8300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.4022 - accuracy: 0.8300\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4842 - accuracy: 0.7300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.4842 - accuracy: 0.7300\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.7200WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.5797 - accuracy: 0.7200\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4458 - accuracy: 0.7700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.4458 - accuracy: 0.7700\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4669 - accuracy: 0.7600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 398ms/step - loss: 0.4669 - accuracy: 0.7600\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4144 - accuracy: 0.8400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.4144 - accuracy: 0.8400\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3637 - accuracy: 0.8300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 395ms/step - loss: 0.3637 - accuracy: 0.8300\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.8700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 390ms/step - loss: 0.3288 - accuracy: 0.8700\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4239 - accuracy: 0.8200WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.4239 - accuracy: 0.8200\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5055 - accuracy: 0.7600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 386ms/step - loss: 0.5055 - accuracy: 0.7600\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.8000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.4177 - accuracy: 0.8000\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.8200WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.4365 - accuracy: 0.8200\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4246 - accuracy: 0.8100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.4246 - accuracy: 0.8100\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.7800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 402ms/step - loss: 0.4269 - accuracy: 0.7800\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.8500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 387ms/step - loss: 0.3731 - accuracy: 0.8500\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4581 - accuracy: 0.7600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 385ms/step - loss: 0.4581 - accuracy: 0.7600\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.8400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.4061 - accuracy: 0.8400\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4608 - accuracy: 0.7500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 378ms/step - loss: 0.4608 - accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4854 - accuracy: 0.7400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.4854 - accuracy: 0.7400\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.8700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 0.3322 - accuracy: 0.8700\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3759 - accuracy: 0.8100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.3759 - accuracy: 0.8100\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3684 - accuracy: 0.8400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.3684 - accuracy: 0.8400\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4203 - accuracy: 0.7900WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.4203 - accuracy: 0.7900\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.8000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.4279 - accuracy: 0.8000\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.8800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 397ms/step - loss: 0.2640 - accuracy: 0.8800\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5085 - accuracy: 0.7100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.5085 - accuracy: 0.7100\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3562 - accuracy: 0.8600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 373ms/step - loss: 0.3562 - accuracy: 0.8600\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3743 - accuracy: 0.8100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.3743 - accuracy: 0.8100\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.8000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.3518 - accuracy: 0.8000\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4265 - accuracy: 0.7700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 383ms/step - loss: 0.4265 - accuracy: 0.7700\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.8500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 377ms/step - loss: 0.3394 - accuracy: 0.8500\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.8700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 370ms/step - loss: 0.3196 - accuracy: 0.8700\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.2947 - accuracy: 0.8700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.2947 - accuracy: 0.8700\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4078 - accuracy: 0.8200WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.4078 - accuracy: 0.8200\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.7700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 0.4832 - accuracy: 0.7700\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3246 - accuracy: 0.8700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.3246 - accuracy: 0.8700\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4204 - accuracy: 0.7800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.4204 - accuracy: 0.7800\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.7700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.4076 - accuracy: 0.7700\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.8100WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.4723 - accuracy: 0.8100\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4010 - accuracy: 0.8400WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.4010 - accuracy: 0.8400\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3151 - accuracy: 0.8700WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 374ms/step - loss: 0.3151 - accuracy: 0.8700\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.4701 - accuracy: 0.7800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 375ms/step - loss: 0.4701 - accuracy: 0.7800\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3564 - accuracy: 0.8500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 371ms/step - loss: 0.3564 - accuracy: 0.8500\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.8200WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.3786 - accuracy: 0.8200\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.7600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "10/10 [==============================] - 4s 372ms/step - loss: 0.5308 - accuracy: 0.7600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16c088ba140>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transfer.compile(loss='binary_crossentropy',optimizer=\"sgd\",metrics=['accuracy'])\n",
    "\n",
    "train_data_dir = './Dane/data/PetImagesTrain'\n",
    "validation_data_dir = './Dane/data/validation'\n",
    "nb_validation_samples = 200\n",
    "nb_train_samples = 50\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2,\n",
    "                                   rotation_range=45, \n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir, \n",
    "                                                    target_size=(h, w), \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                        target_size=(h, w), \n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='binary')\n",
    "\n",
    "history_tr_ag2 = History()\n",
    "early_stopping = EarlyStopping(patience=3,monitor=\"val_loss\")\n",
    "model_transfer.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=epochs, \n",
    "                    validation_data=validation_generator, validation_steps=10, callbacks=[early_stopping, history_tr_ag2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_tr_ag.history['accuracy'], label = \"tarina Adam\")\n",
    "plt.plot(history_tr_ag.history['val_accuracy'], label = \"test Adam\")\n",
    "plt.plot(history_tr_ag2.history['accuracy'], label = \"tarina Adam2\")\n",
    "plt.plot(history_tr_ag2.history['val_accuracy'], label = \"test Adam2\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
