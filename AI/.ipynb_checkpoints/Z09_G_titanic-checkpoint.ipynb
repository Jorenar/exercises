{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from scipy.linalg import LinAlgWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', category=LinAlgWarning)\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# titanic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najpierw zaloguj się do https://www.kaggle.com/ i przejdź do wyzwania https://www.kaggle.com/c/titanic, aby pobrać \n",
    " * train.csv i test.csv. \n",
    "\n",
    "Zapisz je w katalogu datasets/titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "TITANIC_PATH = os.path.join(\"data\", \"Titanic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
    "    csv_path = os.path.join(titanic_path, filename)\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_titanic_data(\"train.csv\")\n",
    "test_data = load_titanic_data(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dane są już podzielone na zestaw treningowy i zestaw testów. \n",
    "* Jednak dane testowe nie zawierają etykiet: Twoim celem jest wyszkolenie najlepszego modelu, który możesz wykorzystać w danych treningowych, następnie dokonanie swoich przewidywań na danych testowych i przesłanie ich do Kaggle, aby zobaczyć ostateczny wynik.\n",
    "\n",
    "Rzućmy okiem na kilka pierwszych rzędów zestawu treningowego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes have the following meaning:\n",
    "\n",
    "* Survived: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
    "* Pclass: passenger class.\n",
    "* Name, Sex, Age: self-explanatory\n",
    "* SibSp: how many siblings & spouses of the passenger aboard the Titanic.\n",
    "* Parch: how many children & parents of the passenger aboard the Titanic.\n",
    "* Ticket: ticket id\n",
    "* Fare: price paid (in pounds)\n",
    "* Cabin: passenger's cabin number\n",
    "* Embarked: where the passenger embarked the Titanic\n",
    "* Let's get more info to see how much data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atrybuty **Age**, **Cabin** oraz **Embarked** są czasami zerowe (mniej niż 891 wartości bez wartości null), szczególnie w przypadku **Cabin** (77% ma wartość zerową). Zignorujemy teraz **Cabin** i skupimy się na reszcie. Atrybut **Age** ma około 19% wartości pustych, więc będziemy musieli zdecydować, co z nimi zrobić. Zastąpienie wartości null medianą wieku wydaje się uzasadnione.\n",
    "\n",
    "Atrybuty **Name** i **Ticket** mogą mieć pewną wartość, ale będą one nieco trudne do przekształcenia w użyteczne liczby. Na razie będziemy je ignorować.\n",
    "\n",
    "Rzućmy okiem na atrybuty liczbowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tylko 38% przeżyło: to wystarczająco blisko do 40%, więc **accuracy** będzie rozsądną miarą do oceny naszego modelu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy, czy etykiety przyjmują wartości 0 lub 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n",
      "----------------------------\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data[\"Survived\"].value_counts())\n",
    "print(\"----------------------------\")\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (891, 11) y.shape: (891,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop(['Survived'], axis=1)\n",
    "y = train_data['Survived'].values\n",
    "np.unique(y)\n",
    "y[ y == ' <=50K'] = 0\n",
    "y[ y == ' >50K'] = 1\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"X.shape: {} y.shape: {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nie zapomnij o etykietach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X.values\n",
    "X_train = X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz rzućmy okiem na wszystkie atrybuty kategoryczne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B96 B98        4\n",
       "G6             4\n",
       "C23 C25 C27    4\n",
       "C22 C26        3\n",
       "F33            3\n",
       "              ..\n",
       "E34            1\n",
       "C7             1\n",
       "C54            1\n",
       "E36            1\n",
       "C148           1\n",
       "Name: Cabin, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Cabin\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347082      7\n",
       "CA. 2343    7\n",
       "1601        7\n",
       "3101295     6\n",
       "CA 2144     6\n",
       "           ..\n",
       "9234        1\n",
       "19988       1\n",
       "2693        1\n",
       "PC 17612    1\n",
       "370376      1\n",
       "Name: Ticket, Length: 681, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Ticket\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    644\n",
       "C    168\n",
       "Q     77\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atrybut **Embarked** mówi nam, gdzie pasażer zaokrętował: C = Cherbourg, Q = Queenstown, S = Southampton.\n",
    "\n",
    "Teraz zbudujmy nasze **pipeline** preprocessingu. \n",
    "\n",
    "Wykorzystamy DataframeSelector aby wybrać określone atrybuty z DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# A class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbudujmy **pipeline** dla atrybutów numerycznych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"Fare\"])),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28.5   ],\n",
       "       [ 13.    ],\n",
       "       [  7.925 ],\n",
       "       [  7.8542],\n",
       "       [ 31.275 ],\n",
       "       [247.5208],\n",
       "       [ 26.55  ],\n",
       "       [ 27.7208],\n",
       "       [  7.8958],\n",
       "       [ 35.5   ],\n",
       "       [ 13.    ],\n",
       "       [ 24.15  ],\n",
       "       [ 12.275 ],\n",
       "       [  7.0542],\n",
       "       [  9.5   ],\n",
       "       [ 26.    ],\n",
       "       [ 90.    ],\n",
       "       [227.525 ],\n",
       "       [ 13.    ],\n",
       "       [ 57.    ],\n",
       "       [ 31.275 ],\n",
       "       [  6.2375],\n",
       "       [  8.6625],\n",
       "       [ 26.25  ],\n",
       "       [  9.5875],\n",
       "       [  7.2292],\n",
       "       [ 22.3583],\n",
       "       [  9.4833],\n",
       "       [120.    ],\n",
       "       [ 14.4583],\n",
       "       [  8.05  ],\n",
       "       [211.5   ],\n",
       "       [  7.25  ],\n",
       "       [ 90.    ],\n",
       "       [  7.725 ],\n",
       "       [ 25.4667],\n",
       "       [ 21.075 ],\n",
       "       [ 30.    ],\n",
       "       [ 61.3792],\n",
       "       [ 26.    ],\n",
       "       [  7.25  ],\n",
       "       [  7.8958],\n",
       "       [ 13.    ],\n",
       "       [ 20.2125],\n",
       "       [ 30.5   ],\n",
       "       [  7.05  ],\n",
       "       [ 14.5   ],\n",
       "       [  7.5208],\n",
       "       [151.55  ],\n",
       "       [ 26.    ],\n",
       "       [  7.925 ],\n",
       "       [ 21.    ],\n",
       "       [262.375 ],\n",
       "       [  7.75  ],\n",
       "       [  7.2292],\n",
       "       [  8.6625],\n",
       "       [  7.775 ],\n",
       "       [ 80.    ],\n",
       "       [  9.8417],\n",
       "       [227.525 ],\n",
       "       [ 12.35  ],\n",
       "       [  0.    ],\n",
       "       [ 26.    ],\n",
       "       [  7.225 ],\n",
       "       [  8.6625],\n",
       "       [  6.4375],\n",
       "       [  9.5   ],\n",
       "       [  8.05  ],\n",
       "       [  7.8958],\n",
       "       [  7.25  ],\n",
       "       [ 30.5   ],\n",
       "       [ 12.475 ],\n",
       "       [ 26.    ],\n",
       "       [  7.75  ],\n",
       "       [  7.2292],\n",
       "       [133.65  ],\n",
       "       [  6.975 ],\n",
       "       [  8.05  ],\n",
       "       [ 77.9583],\n",
       "       [ 10.5   ],\n",
       "       [ 26.    ],\n",
       "       [151.55  ],\n",
       "       [106.425 ],\n",
       "       [ 13.    ],\n",
       "       [  8.6625],\n",
       "       [  0.    ],\n",
       "       [ 26.55  ],\n",
       "       [  8.6625],\n",
       "       [ 26.55  ],\n",
       "       [ 81.8583],\n",
       "       [  7.8958],\n",
       "       [ 11.1333],\n",
       "       [ 27.75  ],\n",
       "       [ 26.25  ],\n",
       "       [153.4625],\n",
       "       [ 26.25  ],\n",
       "       [  8.05  ],\n",
       "       [  8.3   ],\n",
       "       [ 15.05  ],\n",
       "       [110.8833],\n",
       "       [ 13.    ],\n",
       "       [  8.6625],\n",
       "       [  7.05  ],\n",
       "       [133.65  ],\n",
       "       [  0.    ],\n",
       "       [ 15.0458],\n",
       "       [ 39.6875],\n",
       "       [  7.8792],\n",
       "       [ 23.45  ],\n",
       "       [ 26.    ],\n",
       "       [ 11.1333],\n",
       "       [  7.65  ],\n",
       "       [  7.75  ],\n",
       "       [ 15.7417],\n",
       "       [ 15.2458],\n",
       "       [  7.925 ],\n",
       "       [ 51.8625],\n",
       "       [ 15.5   ],\n",
       "       [ 41.5792],\n",
       "       [ 14.4542],\n",
       "       [ 10.5167],\n",
       "       [ 20.525 ],\n",
       "       [ 89.1042],\n",
       "       [ 36.75  ],\n",
       "       [ 10.5   ],\n",
       "       [  8.05  ],\n",
       "       [ 55.4417],\n",
       "       [ 24.15  ],\n",
       "       [ 14.5   ],\n",
       "       [ 26.55  ],\n",
       "       [ 13.    ],\n",
       "       [ 50.    ],\n",
       "       [ 21.    ],\n",
       "       [ 13.8625],\n",
       "       [  7.8958],\n",
       "       [  8.05  ],\n",
       "       [ 10.5   ],\n",
       "       [ 16.7   ],\n",
       "       [ 13.5   ],\n",
       "       [ 36.75  ],\n",
       "       [ 21.075 ],\n",
       "       [ 35.    ],\n",
       "       [  8.05  ],\n",
       "       [ 55.9   ],\n",
       "       [  7.8   ],\n",
       "       [ 10.5   ],\n",
       "       [  7.925 ],\n",
       "       [  7.8542],\n",
       "       [  7.75  ],\n",
       "       [ 34.375 ],\n",
       "       [  7.75  ],\n",
       "       [  7.225 ],\n",
       "       [  7.2292],\n",
       "       [ 18.    ],\n",
       "       [ 13.    ],\n",
       "       [ 26.    ],\n",
       "       [ 47.1   ],\n",
       "       [ 80.    ],\n",
       "       [ 19.5   ],\n",
       "       [  8.6625],\n",
       "       [ 13.5   ],\n",
       "       [ 20.25  ],\n",
       "       [  8.05  ],\n",
       "       [ 31.3875],\n",
       "       [  8.1125],\n",
       "       [  7.8292],\n",
       "       [  7.8958],\n",
       "       [ 59.4   ],\n",
       "       [  7.8958],\n",
       "       [ 79.2   ],\n",
       "       [ 56.4958],\n",
       "       [ 57.9792],\n",
       "       [  7.925 ],\n",
       "       [ 25.4667],\n",
       "       [ 10.5   ],\n",
       "       [ 46.9   ],\n",
       "       [  8.6625],\n",
       "       [ 52.5542],\n",
       "       [ 10.5   ],\n",
       "       [ 29.125 ],\n",
       "       [ 56.4958],\n",
       "       [  9.825 ],\n",
       "       [ 13.    ],\n",
       "       [  7.75  ],\n",
       "       [  7.925 ],\n",
       "       [ 14.4583],\n",
       "       [  7.75  ],\n",
       "       [ 61.175 ],\n",
       "       [ 15.1   ],\n",
       "       [  8.05  ],\n",
       "       [ 66.6   ],\n",
       "       [ 83.1583],\n",
       "       [ 37.0042],\n",
       "       [  7.75  ],\n",
       "       [ 26.    ],\n",
       "       [ 20.525 ],\n",
       "       [  7.25  ],\n",
       "       [ 26.55  ],\n",
       "       [ 16.1   ],\n",
       "       [ 41.5792],\n",
       "       [  7.8958],\n",
       "       [ 57.9792],\n",
       "       [ 27.9   ],\n",
       "       [211.3375],\n",
       "       [106.425 ],\n",
       "       [ 16.1   ],\n",
       "       [  7.7958],\n",
       "       [ 13.    ],\n",
       "       [ 40.125 ],\n",
       "       [  7.05  ],\n",
       "       [  7.75  ],\n",
       "       [ 28.7125],\n",
       "       [ 19.2583],\n",
       "       [ 49.5042],\n",
       "       [ 65.    ],\n",
       "       [ 52.    ],\n",
       "       [ 86.5   ],\n",
       "       [ 13.    ],\n",
       "       [  7.8958],\n",
       "       [ 26.    ],\n",
       "       [ 16.    ],\n",
       "       [ 53.1   ],\n",
       "       [  6.8583],\n",
       "       [ 79.2   ],\n",
       "       [ 19.9667],\n",
       "       [ 13.7917],\n",
       "       [  7.7333],\n",
       "       [113.275 ],\n",
       "       [  8.05  ],\n",
       "       [ 26.    ],\n",
       "       [ 21.075 ],\n",
       "       [  7.8958],\n",
       "       [ 69.55  ],\n",
       "       [ 26.    ],\n",
       "       [ 30.0708],\n",
       "       [ 26.    ],\n",
       "       [  8.0292],\n",
       "       [ 55.    ],\n",
       "       [ 13.    ],\n",
       "       [  7.8958],\n",
       "       [ 39.6   ],\n",
       "       [ 24.    ],\n",
       "       [  7.925 ],\n",
       "       [ 26.    ],\n",
       "       [ 16.1   ],\n",
       "       [  7.8958],\n",
       "       [  7.225 ],\n",
       "       [ 26.25  ],\n",
       "       [ 20.575 ],\n",
       "       [211.3375],\n",
       "       [ 26.25  ],\n",
       "       [ 17.4   ],\n",
       "       [ 26.    ],\n",
       "       [ 22.025 ],\n",
       "       [ 26.    ],\n",
       "       [ 29.7   ],\n",
       "       [ 14.5   ],\n",
       "       [  7.65  ],\n",
       "       [  7.8958],\n",
       "       [  7.0542],\n",
       "       [  0.    ],\n",
       "       [  7.925 ],\n",
       "       [  6.95  ],\n",
       "       [ 15.5   ],\n",
       "       [  0.    ],\n",
       "       [ 25.5875],\n",
       "       [ 26.55  ],\n",
       "       [ 26.    ],\n",
       "       [263.    ],\n",
       "       [ 11.5   ],\n",
       "       [ 21.    ],\n",
       "       [ 11.2417],\n",
       "       [ 18.7875],\n",
       "       [  7.75  ],\n",
       "       [ 10.5   ],\n",
       "       [  7.25  ],\n",
       "       [  7.8958],\n",
       "       [ 26.55  ],\n",
       "       [ 37.0042],\n",
       "       [  7.7958],\n",
       "       [  7.2292],\n",
       "       [  7.75  ],\n",
       "       [ 29.125 ],\n",
       "       [ 13.4167],\n",
       "       [  7.75  ],\n",
       "       [ 13.    ],\n",
       "       [ 15.7417],\n",
       "       [ 73.5   ],\n",
       "       [  7.225 ],\n",
       "       [ 10.5   ],\n",
       "       [  7.75  ],\n",
       "       [164.8667],\n",
       "       [  7.8958],\n",
       "       [ 11.5   ],\n",
       "       [ 27.9   ],\n",
       "       [ 79.65  ],\n",
       "       [ 53.1   ],\n",
       "       [ 71.    ],\n",
       "       [ 69.3   ],\n",
       "       [153.4625],\n",
       "       [  7.8542],\n",
       "       [108.9   ],\n",
       "       [ 14.4   ],\n",
       "       [ 83.1583],\n",
       "       [  7.225 ],\n",
       "       [ 15.5   ],\n",
       "       [  8.6625],\n",
       "       [  6.4958],\n",
       "       [ 12.2875],\n",
       "       [ 13.    ],\n",
       "       [ 31.3875],\n",
       "       [146.5208],\n",
       "       [  7.75  ],\n",
       "       [  7.925 ],\n",
       "       [  7.775 ],\n",
       "       [ 13.8583],\n",
       "       [ 46.9   ],\n",
       "       [ 13.    ],\n",
       "       [  0.    ],\n",
       "       [  7.2292],\n",
       "       [  7.8958],\n",
       "       [ 13.    ],\n",
       "       [ 19.9667],\n",
       "       [ 10.1708],\n",
       "       [ 24.15  ],\n",
       "       [  7.8542],\n",
       "       [ 56.4958],\n",
       "       [  0.    ],\n",
       "       [  8.05  ],\n",
       "       [263.    ],\n",
       "       [  7.2292],\n",
       "       [ 19.2583],\n",
       "       [ 13.    ],\n",
       "       [ 77.2875],\n",
       "       [  7.7417],\n",
       "       [ 39.6875],\n",
       "       [ 17.8   ],\n",
       "       [ 12.475 ],\n",
       "       [ 15.85  ],\n",
       "       [  7.25  ],\n",
       "       [ 12.65  ],\n",
       "       [ 14.5   ],\n",
       "       [  7.25  ],\n",
       "       [  7.225 ],\n",
       "       [ 69.55  ],\n",
       "       [ 26.2875],\n",
       "       [ 13.    ],\n",
       "       [ 18.75  ],\n",
       "       [227.525 ],\n",
       "       [ 18.    ],\n",
       "       [  7.8542],\n",
       "       [ 90.    ],\n",
       "       [ 30.    ],\n",
       "       [ 42.4   ],\n",
       "       [ 24.15  ],\n",
       "       [  7.775 ],\n",
       "       [  7.3125],\n",
       "       [  7.8958],\n",
       "       [ 23.    ],\n",
       "       [ 13.    ],\n",
       "       [  7.1417],\n",
       "       [ 12.35  ],\n",
       "       [ 15.2458],\n",
       "       [  9.5   ],\n",
       "       [164.8667],\n",
       "       [ 13.    ],\n",
       "       [  7.925 ],\n",
       "       [512.3292],\n",
       "       [ 69.55  ],\n",
       "       [ 23.25  ],\n",
       "       [512.3292],\n",
       "       [ 39.6875],\n",
       "       [  7.55  ],\n",
       "       [ 14.4   ],\n",
       "       [ 33.    ],\n",
       "       [ 24.15  ],\n",
       "       [  7.225 ],\n",
       "       [  8.05  ],\n",
       "       [  7.775 ],\n",
       "       [  8.05  ],\n",
       "       [ 73.5   ],\n",
       "       [ 29.125 ],\n",
       "       [ 29.125 ],\n",
       "       [  8.05  ],\n",
       "       [ 21.6792],\n",
       "       [ 25.9292],\n",
       "       [  7.75  ],\n",
       "       [ 34.0208],\n",
       "       [ 16.1   ],\n",
       "       [ 46.9   ],\n",
       "       [  8.05  ],\n",
       "       [  8.05  ],\n",
       "       [  9.35  ],\n",
       "       [  7.225 ],\n",
       "       [ 33.    ],\n",
       "       [ 18.75  ],\n",
       "       [  8.6625],\n",
       "       [ 15.5   ],\n",
       "       [ 25.4667],\n",
       "       [  8.05  ],\n",
       "       [ 26.55  ],\n",
       "       [ 21.075 ],\n",
       "       [ 19.2583],\n",
       "       [  7.2292],\n",
       "       [  8.05  ],\n",
       "       [ 23.    ],\n",
       "       [ 27.7208],\n",
       "       [ 14.5   ],\n",
       "       [  9.5   ],\n",
       "       [  9.5875],\n",
       "       [ 11.5   ],\n",
       "       [ 78.85  ],\n",
       "       [  7.925 ],\n",
       "       [ 23.45  ],\n",
       "       [  7.775 ],\n",
       "       [ 30.    ],\n",
       "       [  8.05  ],\n",
       "       [ 39.    ],\n",
       "       [  7.7333],\n",
       "       [  7.775 ],\n",
       "       [ 14.4542],\n",
       "       [ 10.5   ],\n",
       "       [ 39.    ],\n",
       "       [  8.6542],\n",
       "       [  7.7333],\n",
       "       [ 24.15  ],\n",
       "       [ 15.    ],\n",
       "       [ 31.275 ],\n",
       "       [ 26.    ],\n",
       "       [ 66.6   ],\n",
       "       [ 15.85  ],\n",
       "       [ 29.7   ],\n",
       "       [ 18.7875],\n",
       "       [  9.5   ],\n",
       "       [ 10.5   ],\n",
       "       [ 11.1333],\n",
       "       [ 13.    ],\n",
       "       [  7.2292],\n",
       "       [ 27.75  ],\n",
       "       [ 16.1   ],\n",
       "       [ 12.35  ],\n",
       "       [  7.775 ],\n",
       "       [ 51.4792],\n",
       "       [  7.925 ],\n",
       "       [ 13.    ],\n",
       "       [ 79.65  ],\n",
       "       [ 31.275 ],\n",
       "       [151.55  ],\n",
       "       [  7.925 ],\n",
       "       [ 12.525 ],\n",
       "       [ 26.    ],\n",
       "       [ 79.2   ],\n",
       "       [110.8833],\n",
       "       [  8.05  ],\n",
       "       [ 34.375 ],\n",
       "       [  7.7958],\n",
       "       [  8.6625],\n",
       "       [ 56.4958],\n",
       "       [  7.8958],\n",
       "       [ 15.9   ],\n",
       "       [ 13.    ],\n",
       "       [135.6333],\n",
       "       [ 15.5   ],\n",
       "       [ 13.    ],\n",
       "       [ 86.5   ],\n",
       "       [ 41.5792],\n",
       "       [  6.75  ],\n",
       "       [  7.775 ],\n",
       "       [  8.4042],\n",
       "       [153.4625],\n",
       "       [ 20.25  ],\n",
       "       [  8.85  ],\n",
       "       [  7.925 ],\n",
       "       [ 30.0708],\n",
       "       [ 39.    ],\n",
       "       [  6.4958],\n",
       "       [263.    ],\n",
       "       [  7.775 ],\n",
       "       [  8.05  ],\n",
       "       [ 20.575 ],\n",
       "       [  6.975 ],\n",
       "       [ 26.25  ],\n",
       "       [  9.825 ],\n",
       "       [  7.8958],\n",
       "       [211.3375],\n",
       "       [  7.8875],\n",
       "       [ 10.5   ],\n",
       "       [ 69.3   ],\n",
       "       [ 10.5   ],\n",
       "       [ 10.5   ],\n",
       "       [  0.    ],\n",
       "       [ 16.1   ],\n",
       "       [  9.35  ],\n",
       "       [  8.1375],\n",
       "       [ 46.9   ],\n",
       "       [ 69.55  ],\n",
       "       [ 56.4958],\n",
       "       [  7.775 ],\n",
       "       [  0.    ],\n",
       "       [  9.5   ],\n",
       "       [ 78.2667],\n",
       "       [  8.05  ],\n",
       "       [ 13.5   ],\n",
       "       [ 23.    ],\n",
       "       [ 30.5   ],\n",
       "       [ 52.    ],\n",
       "       [135.6333],\n",
       "       [  5.    ],\n",
       "       [ 12.475 ],\n",
       "       [ 31.3875],\n",
       "       [  0.    ],\n",
       "       [  8.05  ],\n",
       "       [ 14.    ],\n",
       "       [  7.55  ],\n",
       "       [  7.8958],\n",
       "       [  7.2292],\n",
       "       [  7.8792],\n",
       "       [512.3292],\n",
       "       [ 77.9583],\n",
       "       [ 30.5   ],\n",
       "       [  9.5   ],\n",
       "       [  7.25  ],\n",
       "       [  7.8958],\n",
       "       [ 90.    ],\n",
       "       [ 69.55  ],\n",
       "       [ 26.    ],\n",
       "       [ 27.75  ],\n",
       "       [ 16.1   ],\n",
       "       [108.9   ],\n",
       "       [ 16.1   ],\n",
       "       [  7.8958],\n",
       "       [ 39.6875],\n",
       "       [  8.5167],\n",
       "       [ 10.5   ],\n",
       "       [  7.125 ],\n",
       "       [ 76.7292],\n",
       "       [ 65.    ],\n",
       "       [ 39.6   ],\n",
       "       [ 31.275 ],\n",
       "       [ 55.9   ],\n",
       "       [ 15.85  ],\n",
       "       [ 10.5   ],\n",
       "       [110.8833],\n",
       "       [ 69.55  ],\n",
       "       [  7.2292],\n",
       "       [ 52.    ],\n",
       "       [ 71.    ],\n",
       "       [ 33.5   ],\n",
       "       [  6.75  ],\n",
       "       [  7.4958],\n",
       "       [ 14.5   ],\n",
       "       [ 56.4958],\n",
       "       [  8.05  ],\n",
       "       [  8.05  ],\n",
       "       [ 14.4542],\n",
       "       [  8.05  ],\n",
       "       [ 57.    ],\n",
       "       [ 26.55  ],\n",
       "       [  7.225 ],\n",
       "       [  7.2292],\n",
       "       [ 15.85  ],\n",
       "       [  7.925 ],\n",
       "       [ 26.    ],\n",
       "       [  7.7958],\n",
       "       [ 27.    ],\n",
       "       [  8.05  ],\n",
       "       [ 27.9   ],\n",
       "       [  8.6833],\n",
       "       [ 15.5   ],\n",
       "       [  7.8958],\n",
       "       [ 26.    ],\n",
       "       [  8.6625],\n",
       "       [ 46.9   ],\n",
       "       [ 23.    ],\n",
       "       [  7.7375],\n",
       "       [  7.75  ],\n",
       "       [  7.75  ],\n",
       "       [  7.6292],\n",
       "       [  7.75  ],\n",
       "       [  7.75  ],\n",
       "       [  9.5   ],\n",
       "       [ 13.    ],\n",
       "       [263.    ],\n",
       "       [  7.8958],\n",
       "       [ 83.475 ],\n",
       "       [ 15.9   ],\n",
       "       [  4.0125],\n",
       "       [ 13.    ],\n",
       "       [ 13.    ],\n",
       "       [  0.    ],\n",
       "       [  7.7958],\n",
       "       [  7.25  ],\n",
       "       [151.55  ],\n",
       "       [  9.2167],\n",
       "       [ 83.475 ],\n",
       "       [  8.6625],\n",
       "       [ 35.5   ],\n",
       "       [ 22.3583],\n",
       "       [ 50.4958],\n",
       "       [ 93.5   ],\n",
       "       [ 27.7208],\n",
       "       [  7.8542],\n",
       "       [  7.7333],\n",
       "       [  9.475 ],\n",
       "       [ 30.5   ],\n",
       "       [  7.775 ],\n",
       "       [ 26.55  ],\n",
       "       [120.    ],\n",
       "       [  7.925 ],\n",
       "       [ 76.7292],\n",
       "       [134.5   ],\n",
       "       [ 53.1   ],\n",
       "       [  7.775 ],\n",
       "       [ 53.1   ],\n",
       "       [ 27.7208],\n",
       "       [ 26.2875],\n",
       "       [ 10.4625],\n",
       "       [ 21.    ],\n",
       "       [  8.05  ],\n",
       "       [  7.8958],\n",
       "       [ 30.    ],\n",
       "       [135.6333],\n",
       "       [ 69.55  ],\n",
       "       [ 15.75  ],\n",
       "       [ 26.55  ],\n",
       "       [  7.925 ],\n",
       "       [  8.05  ],\n",
       "       [ 14.4542],\n",
       "       [ 21.    ],\n",
       "       [  7.8542],\n",
       "       [  7.8958],\n",
       "       [ 24.15  ],\n",
       "       [ 12.    ],\n",
       "       [ 71.2833],\n",
       "       [  7.2292],\n",
       "       [  7.8958],\n",
       "       [  9.    ],\n",
       "       [ 10.4625],\n",
       "       [ 82.1708],\n",
       "       [  7.75  ],\n",
       "       [ 22.525 ],\n",
       "       [ 26.    ],\n",
       "       [  8.05  ],\n",
       "       [ 75.25  ],\n",
       "       [  7.8542],\n",
       "       [ 35.5   ],\n",
       "       [  8.05  ],\n",
       "       [ 13.    ],\n",
       "       [  7.75  ],\n",
       "       [ 15.5   ],\n",
       "       [ 31.275 ],\n",
       "       [  7.8542],\n",
       "       [ 27.    ],\n",
       "       [ 13.    ],\n",
       "       [ 29.7   ],\n",
       "       [ 55.    ],\n",
       "       [ 10.5   ],\n",
       "       [  7.8958],\n",
       "       [  6.45  ],\n",
       "       [ 91.0792],\n",
       "       [  9.    ],\n",
       "       [ 86.5   ],\n",
       "       [ 18.75  ],\n",
       "       [  7.125 ],\n",
       "       [  7.8958],\n",
       "       [ 13.5   ],\n",
       "       [ 39.6875],\n",
       "       [  7.8958],\n",
       "       [ 30.    ],\n",
       "       [  7.65  ],\n",
       "       [ 52.    ],\n",
       "       [ 76.7292],\n",
       "       [  7.75  ],\n",
       "       [ 27.75  ],\n",
       "       [  9.8375],\n",
       "       [  7.75  ],\n",
       "       [ 13.    ],\n",
       "       [ 26.55  ],\n",
       "       [ 13.    ],\n",
       "       [  7.8958],\n",
       "       [  7.75  ],\n",
       "       [ 16.1   ],\n",
       "       [  7.75  ],\n",
       "       [ 13.    ],\n",
       "       [ 73.5   ],\n",
       "       [  7.775 ],\n",
       "       [  0.    ],\n",
       "       [  7.25  ],\n",
       "       [ 13.    ],\n",
       "       [  8.3625],\n",
       "       [ 24.    ],\n",
       "       [  7.225 ],\n",
       "       [  7.8958],\n",
       "       [  7.4958],\n",
       "       [ 52.5542],\n",
       "       [ 26.    ],\n",
       "       [  8.05  ],\n",
       "       [  8.05  ],\n",
       "       [ 10.5   ],\n",
       "       [ 23.25  ],\n",
       "       [  7.75  ],\n",
       "       [  0.    ],\n",
       "       [  8.05  ],\n",
       "       [  8.05  ],\n",
       "       [ 26.    ],\n",
       "       [227.525 ],\n",
       "       [ 46.9   ],\n",
       "       [  7.65  ],\n",
       "       [ 31.    ],\n",
       "       [ 14.1083],\n",
       "       [120.    ],\n",
       "       [ 77.2875]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Będziemy także potrzebować imputera do kategorycznych kolumn  napisowych (zwykły Imputer nie działa na tych kolumnach):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired from stackoverflow.com/questions/25239958\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz możemy zbudować **pipeline** dla atrybutów kategorycznych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from future_encoders import OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"Cabin\", \"Embarked\", \"Ticket\", \"Sex\"])),\n",
    "        (\"imputer\", MostFrequentImputer()),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False, handle_unknown = 'ignore')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na koniec połączmy powyższe podejścia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz mamy fajny **pipeline** przetwarzania wstępnego, który pobiera dane wejściowe i zwraca dane wyjściowe złorzone z liczb, które możemy podać do dowolnego modelu uczenia maszynowego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Robimy StratifiedKFold i znajdujemy optymalne parametry dla\n",
    "\n",
    "* SVM z jądrem rbf\n",
    "* SVM z jądrem poly\n",
    "* SVM liniowego\n",
    "* Regresji logistycznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5) #, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 10, 'classifier__gamma': 0.1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('preprocessing', preprocess_pipeline), ('classifier', SVC(kernel='rbf'))])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_1 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_1.fit(X_train, y_train)\n",
    "grid_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 100, 'classifier__degree': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', SVC(kernel='poly'))])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'classifier__degree': list(range(1,7)),\n",
    "}\n",
    "grid_2 = GridSearchCV(pipe, param_grid, cv=kfold)\n",
    "grid_2.fit(X_train, y_train)\n",
    "grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 10, 'classifier__tol': 0.1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('preprocessing', preprocess_pipeline), ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'classifier__tol': [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "}\n",
    "\n",
    "grid_3 = GridSearchCV(pipe, param_grid, cv=kfold)\n",
    "\n",
    "grid_3.fit(X_train, y_train)\n",
    "grid_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 100}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "pipe = Pipeline([\n",
    "    ('preprocessing', preprocess_pipeline),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "param_grid = {\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "}\n",
    "grid_4 = GridSearchCV(pipe, param_grid, cv=kfold)\n",
    "grid_4.fit(X_train, y_train)\n",
    "grid_4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM rfb\n",
      "precision_score: 0.7846153846153846\n",
      "recall_score: 0.6891891891891891\n",
      "f1_score: 0.7338129496402878\n",
      "accuracy_score: 0.7932960893854749\n",
      "SVM poly\n",
      "precision_score: 0.7536231884057971\n",
      "recall_score: 0.7027027027027027\n",
      "f1_score: 0.7272727272727273\n",
      "accuracy_score: 0.7821229050279329\n",
      "SVM linear\n",
      "precision_score: 0.8181818181818182\n",
      "recall_score: 0.7297297297297297\n",
      "f1_score: 0.7714285714285715\n",
      "accuracy_score: 0.8212290502793296\n",
      "Logistic regression\n",
      "precision_score: 0.7910447761194029\n",
      "recall_score: 0.7162162162162162\n",
      "f1_score: 0.7517730496453902\n",
      "accuracy_score: 0.8044692737430168\n"
     ]
    }
   ],
   "source": [
    "from sklearn import  metrics\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('SVM rfb', grid_1.best_estimator_))\n",
    "models.append(('SVM poly', grid_2.best_estimator_))\n",
    "models.append(('SVM linear', grid_3.best_estimator_))\n",
    "models.append(('Logistic regression', grid_4.best_estimator_))\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"precision_score: {}\".format(metrics.precision_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test, model.predict(X_test)) ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test, model.predict(X_test)) ))\n",
    "    precision_score.append(metrics.precision_score(y_test, model.predict(X_test)))\n",
    "    recall_score.append(metrics.recall_score(y_test, model.predict(X_test)))\n",
    "    f1_score.append( metrics.f1_score(y_test, model.predict(X_test)))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM rbf</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.689189</td>\n",
       "      <td>0.733813</td>\n",
       "      <td>0.793296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM poly</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.782123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM linear</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.821229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.751773</td>\n",
       "      <td>0.804469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Method  precision_score  recall_score  f1_score  \\\n",
       "0              SVM rbf         0.784615      0.689189  0.733813   \n",
       "1             SVM poly         0.753623      0.702703  0.727273   \n",
       "2           SVM linear         0.818182      0.729730  0.771429   \n",
       "3  Logistic Regression         0.791045      0.716216  0.751773   \n",
       "\n",
       "   accuracy_score  \n",
       "0        0.793296  \n",
       "1        0.782123  \n",
       "2        0.821229  \n",
       "3        0.804469  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'precision_score': precision_score, \n",
    "     'recall_score': recall_score, \n",
    "     'f1_score': f1_score,\n",
    "     'accuracy_score' : accuracy_score\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "df.insert(loc=0, column='Method', value=['SVM rbf', 'SVM poly', 'SVM linear', 'Logistic Regression'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
