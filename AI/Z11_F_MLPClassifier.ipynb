{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from matplotlib import MatplotlibDeprecationWarning\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FitFailedWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', category=LinAlgWarning)\n",
    "warnings.filterwarnings(action='ignore', category=MatplotlibDeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wielowarstwowa sieć neuronowa\n",
    "\n",
    "(*Multilayer perceptron*, *feedforward neural network*)\n",
    "\n",
    "\n",
    "\n",
    "**Uwaga:** \"Input layer\" pomimo tego, że ma w nazwie słowo \"warstwa\", to tak naprawdę to nie jest żadna warstwa sieci... To są po prostu dane wejściowe... Niestety przyjęło się literaturze nazywanie tego w ten sposób, co jest mylące :(\n",
    "\n",
    "\n",
    "Sieci uczy sie metodą spadku gradientu (pewnymi wariantami tej metody). Uczenie wykorzystuje algorytm **propagacji wstecznej** (https://en.wikipedia.org/wiki/Backpropagation).\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "**Uwaga!** Sieci neuronowe absolutnie zawsze wymagają zestandaryzowanych danych! Niezależnie od tego czy wykorzystujemy regularyzację czy nie i niezależnie od typu sieci!\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Fakt matematyczny: jednowarstwową siecią możemy otrzymać dowolny kształt. \n",
    "\n",
    "Co z tego wynika? To, że (teoretycznie) zawsze wystarczy sieć jednowarstwowa (odpowiednio duża). W praktyce rzeczywiście z reguły wystarcza jedna warstwa, ale mimo wszystko zawsze warto sprawdzić czy 2 (lub 3) nie zadziałają przypadkiem lepiej. Przy czym jeżeli dla dwóch wartsw jest gorzej, to nie ma sensu sprawdzać dla większej ilości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "* Wczytaj zbiór danych\n",
    "* Podziel dane na train test\n",
    "* Wykonaj uczenie modeli (dobierz najlepsze parametry)\n",
    "    * LogisticRegression\n",
    "    * LinearSVC\n",
    "    * SVC\n",
    "    * KNeighborsClassifier\n",
    "    * DecisionTreeClassifier\n",
    "    * RandomForestClassifier\n",
    "    * BaggingClassifier\n",
    "    * ExtraTreesClassifier\n",
    "    * AdaBoostClassifier\n",
    "    * GradientBoostingClassifier\n",
    "    * VotingClassifier\n",
    "    * xgboost.XGBClassifier\n",
    "* Porównaj wyniki na zbiorze uczącym    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "0.3489583333333333\n"
     ]
    }
   ],
   "source": [
    "dataset = np.loadtxt('data/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "print(X.shape)\n",
    "print(np.mean(Y))\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed, shuffle=True)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed=123\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.01, 'preprocessing': StandardScaler()}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', LinearSVC(C=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_1 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_1.fit(X_train, y_train)\n",
    "grid_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 10,\n",
       " 'classifier__gamma': 0.001,\n",
       " 'preprocessing': StandardScaler()}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', SVC(C=1, kernel='rbf', gamma=0.001))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_2 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_2.fit(X_train, y_train)\n",
    "grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 100, 'classifier__penalty': 'l2', 'preprocessing': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', LogisticRegression(penalty='l2', C=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'classifier__penalty': ['l1', 'l2', 'elasticnet']\n",
    "}\n",
    "\n",
    "grid_3 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_3.fit(X_train, y_train)\n",
    "grid_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__n_neighbors': 9, 'preprocessing': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', KNeighborsClassifier(n_neighbors=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "grid_4 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_4.fit(X_train, y_train)\n",
    "grid_4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__criterion': 'entropy',\n",
       " 'classifier__max_depth': 5,\n",
       " 'classifier__max_features': 'log2',\n",
       " 'classifier__min_samples_leaf': 9,\n",
       " 'classifier__min_samples_split': 9,\n",
       " 'preprocessing': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', DecisionTreeClassifier(max_depth=1, max_features=1, min_samples_leaf=1, min_samples_split=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__criterion': ['gini', 'entropy'],\n",
    "            'classifier__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__max_features': [None, 'auto', 'log2', 'sqrt'],\n",
    "            'classifier__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "}\n",
    "\n",
    "grid_5 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_5.fit(X_train, y_train)\n",
    "grid_5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', RandomForestClassifier(n_estimators=1, max_depth=1, max_features=1, min_samples_leaf=1, min_samples_split=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__criterion': ['gini', 'entropy'],\n",
    "            'classifier__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__max_features': [None, 'auto', 'log2', 'sqrt'],\n",
    "            'classifier__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "            'classifier__n_estimators': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "}\n",
    "\n",
    "grid_6 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_6.fit(X_train, y_train)\n",
    "grid_6.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=1, random_state=0, max_features=None, min_samples_leaf=1, min_samples_split=2), n_estimators=10, random_state=0))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__base_estimator__criterion': ['gini', 'entropy'],\n",
    "            'classifier__base_estimator__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__base_estimator__max_features': [None, 'auto', 'log2', 'sqrt'],\n",
    "            'classifier__base_estimator__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__base_estimator__min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "            'classifier__n_estimators': [1, 10, 1007\n",
    "}\n",
    "\n",
    "grid_7 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_7.fit(X_train, y_train)\n",
    "grid_7.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', ExtraTreeClassifier(max_depth=1, max_features=1, min_samples_leaf=1, min_samples_split=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__criterion': ['gini', 'entropy'],\n",
    "            'classifier__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__max_features': [None, 'auto', 'log2', 'sqrt'],\n",
    "            'classifier__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "}\n",
    "\n",
    "grid_8 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_8.fit(X_train, y_train)\n",
    "grid_8.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy', max_depth=1, random_state=0, max_features=None, min_samples_leaf=1, min_samples_split=2), n_estimators=10, random_state=0))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__base_estimator__criterion': ['gini', 'entropy'],\n",
    "            'classifier__base_estimator__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__base_estimator__max_features': [None, 'auto', 'log2', 'sqrt'],\n",
    "            'classifier__base_estimator__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__base_estimator__min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "            'classifier__n_estimators': [1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_9 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_9.fit(X_train, y_train)\n",
    "grid_9.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', GradientBoostingClassifier(learning_rate=0.1, max_depth=1, max_features=1, min_samples_leaf=1, min_samples_split=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__criterion': ['friedman_mse', 'mse', 'mae'],\n",
    "            'classifier__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__max_features': [None, 'auto', 'log2', 'sqrt'],\n",
    "            'classifier__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "            'classifier__n_estimators': [1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_10 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_10.fit(X_train, y_train)\n",
    "grid_10.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1, colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=1, min_child_weight=1, missing=None, n_estimators=10, n_jobs=1, nthread=-1, objective='binary:logistic', random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True, subsample=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__base_score': [0.5],\n",
    "            'classifier__booster': ['gbtree'],\n",
    "            'classifier__colsample_bylevel': [1],\n",
    "            'classifier__colsample_bytree': [1],\n",
    "            'classifier__gamma': [0],\n",
    "            'classifier__learning_rate': [0.1],\n",
    "            'classifier__max_delta_step': [0],\n",
    "            'classifier__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__min_child_weight': [1],\n",
    "            'classifier__n_estimators': [1, 10, 100],\n",
    "            'classifier__subsample': [1]\n",
    "}\n",
    "\n",
    "grid_11 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_11.fit(X_train, y_train)\n",
    "grid_11.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', XGBClassifier(nthread=-1,base_score=0.5, booster='gbtree', colsample_bylevel=1, colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=1, min_child_weight=1, missing=None, n_estimators=10, n_jobs=1, objective='reg:squarederror', random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True, subsample=1))])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__base_score': [0.5],\n",
    "            'classifier__booster': ['gbtree'],\n",
    "            'classifier__colsample_bylevel': [1],\n",
    "            'classifier__colsample_bytree': [1],\n",
    "            'classifier__gamma': [0],\n",
    "            'classifier__learning_rate': [0.1],\n",
    "            'classifier__max_delta_step': [0],\n",
    "            'classifier__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "            'classifier__min_child_weight': [1],\n",
    "            'classifier__n_estimators': [1, 10, 100],\n",
    "            'classifier__subsample': [1]\n",
    "}\n",
    "\n",
    "grid_12 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_12.fit(X_train, y_train)\n",
    "grid_12.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('rf', grid_1.best_estimator_),\n",
    "                                          ('et', grid_2.best_estimator_),\n",
    "                                          ('ada', grid_3.best_estimator_),\n",
    "                                          ('gb', grid_4.best_estimator_),\n",
    "                                          ('xgb', grid_5.best_estimator_),\n",
    "                                          ('knn', grid_6.best_estimator_),\n",
    "                                          ('lr', grid_7.best_estimator_),\n",
    "                                          ('svm', grid_8.best_estimator_),\n",
    "                                          ('gbc', grid_9.best_estimator_),\n",
    "                                          ('xgbc', grid_10.best_estimator_),\n",
    "                                          ('xgbr', grid_11.best_estimator_),\n",
    "                                          ('xgbrf', grid_12.best_estimator_)],\n",
    "                              voting='soft',\n",
    "                              weights=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  metrics\n",
    "\n",
    "models = []\n",
    "models.append(('SVM linear', grid_1.best_estimator_))\n",
    "models.append(('SVM rbf', grid_2.best_estimator_))\n",
    "models.append(('LR', grid_3.best_estimator_))\n",
    "models.append(('KNN', grid_4.best_estimator_))\n",
    "models.append(('DecisionTreeClassifier', grid_5.best_estimator_))\n",
    "models.append(('BaggingClassifier', grid_6.best_estimator_))\n",
    "models.append(('RandomForestClassifier', grid_7.best_estimator_))\n",
    "models.append(('ExtraTreesClassifier', grid_8.best_estimator_))\n",
    "models.append(('AdaBoostClassifier', grid_9.best_estimator_))\n",
    "models.append(('GradientBoostingClassifier', grid_10.best_estimator_))\n",
    "models.append(('XGBClassifier', grid_11.best_estimator_))\n",
    "models.append(('XGBClassifier r2', grid_12.best_estimator_))\n",
    "models.append(('voting_clf', voting_clf))\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "roc_auc_score = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"precision_score: {}\".format(metrics.precision_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test , model.predict(X_test)) ))\n",
    "    \n",
    "    if (name == 'SVM linear'):\n",
    "        print(\"roc_auc_score: {}\".format( metrics.roc_auc_score(y_test , model.decision_function(X_test)) ))            \n",
    "    else:\n",
    "        print(\"roc_auc_score: {}\".format( metrics.roc_auc_score(y_test , model.predict_proba(X_test)[:,1]) ))\n",
    "    \n",
    "    precision_score.append(metrics.precision_score(y_test , model.predict(X_test)))\n",
    "    recall_score.append(metrics.recall_score(y_test , model.predict(X_test)))\n",
    "    f1_score.append( metrics.f1_score(y_test , model.predict(X_test)))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test , model.predict(X_test)))\n",
    "    if (name == 'SVM linear'):\n",
    "        roc_auc_score.append(metrics.roc_auc_score(y_test , model.decision_function(X_test)))        \n",
    "    else:    \n",
    "        roc_auc_score.append(metrics.roc_auc_score(y_test , model.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {'precision_score': precision_score, \n",
    "     'recall_score': recall_score, \n",
    "     'f1_score': f1_score,\n",
    "     'accuracy_score' : accuracy_score,\n",
    "     'roc_auc_score' : roc_auc_score\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "df.insert(loc=0, column='Method', value=['SVM linear'])#,'SVM rbf','LR','KNN', 'DecisionTreeClassifier','BaggingClassifier','RandomForestClassifier','ExtraTreesClassifier', 'AdaBoostClassifier','GradientBoostingClassifier','XGBClassifier','XGBClassifier r', 'voting'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPClassifier\n",
    "\n",
    "Dodajmy model sieci neuronowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier((20,10))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_test)[:,1]\n",
    "predictions = y_pred.round()\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0), \"AUC: \", metrics.roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Wykonaj Walidację krzyżową"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('classifier', MLPClassifier())])\n",
    "\n",
    "param_grid = {\n",
    "            'preprocessing': [StandardScaler(), None],\n",
    "            'classifier__hidden_layer_sizes': [(20,10)],\n",
    "            'classifier__learning_rate_init': [0.001],#, 0.01, 0.1],\n",
    "            'classifier__max_iter': [100],\n",
    "            'classifier__batch_size': [8, 16,32],\n",
    "}\n",
    "\n",
    "grid_2 = GridSearchCV(pipe, param_grid, cv=kfold, return_train_score=True)\n",
    "\n",
    "grid_2.fit(X_train, y_train)\n",
    "grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, grid_2.best_estimator_.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import  metrics\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('SVM linear', grid_1.best_estimator_))\n",
    "models.append(('SVM rbf', grid_2.best_estimator_))\n",
    "models.append(('LR', grid_3.best_estimator_))\n",
    "models.append(('KNN', grid_4.best_estimator_))\n",
    "models.append(('DecisionTreeClassifier', grid_5.best_estimator_))\n",
    "models.append(('BaggingClassifier', grid_6.best_estimator_))\n",
    "models.append(('RandomForestClassifier', grid_7.best_estimator_))\n",
    "models.append(('ExtraTreesClassifier', grid_8.best_estimator_))\n",
    "models.append(('AdaBoostClassifier', grid_9.best_estimator_))\n",
    "models.append(('GradientBoostingClassifier', grid_10.best_estimator_))\n",
    "models.append(('XGBClassifier', grid_11.best_estimator_))\n",
    "models.append(('XGBClassifier r2', grid_12.best_estimator_))\n",
    "models.append(('voting_clf', voting_clf))\n",
    "models.append(('MLP', grid_14.best_estimator_))\n",
    "\n",
    "precision_score = []\n",
    "recall_score = []\n",
    "f1_score = []\n",
    "accuracy_score = []\n",
    "roc_auc_score = []\n",
    "for name, model in models:\n",
    "    print(name)\n",
    "    print(\"precision_score: {}\".format(metrics.precision_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"recall_score: {}\".format( metrics.recall_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"f1_score: {}\".format( metrics.f1_score(y_test , model.predict(X_test)) ))\n",
    "    print(\"accuracy_score: {}\".format( metrics.accuracy_score(y_test , model.predict(X_test)) ))\n",
    "    \n",
    "    if (name == 'SVM linear'):\n",
    "        print(\"roc_auc_score: {}\".format( metrics.roc_auc_score(y_test , model.decision_function(X_test)) ))            \n",
    "    else:\n",
    "        print(\"roc_auc_score: {}\".format( metrics.roc_auc_score(y_test , model.predict_proba(X_test)[:,1]) ))\n",
    "    \n",
    "    precision_score.append(metrics.precision_score(y_test , model.predict(X_test)))\n",
    "    recall_score.append(metrics.recall_score(y_test , model.predict(X_test)))\n",
    "    f1_score.append( metrics.f1_score(y_test , model.predict(X_test)))\n",
    "    accuracy_score.append(metrics.accuracy_score(y_test , model.predict(X_test)))\n",
    "    if (name == 'SVM linear'):\n",
    "        roc_auc_score.append(metrics.roc_auc_score(y_test , model.decision_function(X_test)))        \n",
    "    else:    \n",
    "        roc_auc_score.append(metrics.roc_auc_score(y_test , model.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {'precision_score': precision_score, \n",
    "     'recall_score': recall_score, \n",
    "     'f1_score': f1_score,\n",
    "     'accuracy_score' : accuracy_score,\n",
    "     'roc_auc_score' : roc_auc_score\n",
    "    }\n",
    "df = pd.DataFrame(data=d)\n",
    "df.insert(loc=0, column='Method', value=['SVM linear','SVM rbf','LR','KNN', 'DecisionTreeClassifier','BaggingClassifier','RandomForestClassifier','ExtraTreesClassifier', 'AdaBoostClassifier','GradientBoostingClassifier','XGBClassifier','XGBClassifier r', 'voting', 'MLP'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytaj dane treningowe i testowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "\n",
    "\n",
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop([\"fnlwgt\"],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Porównaj wyniki sieci na:\n",
    "* oryginalnych danych \n",
    "* na wystandaryzowanych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier((20,10))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_test)[:,1]\n",
    "predictions = y_pred.round()\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0), \"AUC: \", metrics.roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "X_test.shape\n",
    "\n",
    "model = MLPClassifier((20,10))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict_proba(X_test)[:,1]\n",
    "predictions = y_pred.round()\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0), \"AUC: \", metrics.roc_auc_score(y_score=y_pred,y_true=y_test))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
