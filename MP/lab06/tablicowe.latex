\documentclass[12pt]{article}

\usepackage[a4paper, vmargin=50pt, hmargin=70pt]{geometry}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{polski}

\usepackage{tikz}

\usepackage{listings}

\setlength{\parskip}{1em}
\setlength{\parindent}{0pt}

\lstdefinestyle{mystyle}{
    breakatwhitespace=false,
    keepspaces=true,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4
}

\lstset{style=mystyle}

\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}

\date{}
\title{}
\author{Jakub Łukasiewicz}

\begin{document}

\maketitle

\section*{Rekurencja ogonowa}

Jest to rodzaj rekurencji, w której ostatnią operacją jest wywołanie samej siebie,
bądź zwrócenie wyniku. Rekurencja tego typu jest zazwyczaj łatwo optymalizowalna
na iterację (co w przypadku języków kompilowanych, kompilator nierzadko robi).

Technika ta jest powszechnie używana w językach funkcyjnych, natomiast w dialektach
innego rodzaju, uważana jest raczej za niezręczne zastosowanie rekurencji.

Przykład rekurencyjnego wyliczania silni:

\lstinputlisting[language=Java]{silnia.java}

\newpage
\section*{Dziel i zwyciężaj - megresort}

Metody \textit{dziel i zwyciężaj} polegają na rekurencyjnym dzieleniu problemu
na mniejsze, tego samego typu, dopóki nie będą dostatecznie małe do prostego
rozwiązania. Następnie tak otrzymane wyniki scala się, otrzymując rozwiązanie
początkowego problemu.

Jako przykład weźmiemy algorytm sortowania przez scalanie (megesort).

\begin{verbatim}
   {7, 4, 1, 3, 5, 6, 2}  | nieposortowana tablica
         /      \
   {7, 4, 1}   {3, 5, 6, 2}
  /     \          /    \
{7}  {4, 1}    {3, 5}  {6, 2}
 |     / \       / \    /  \
{7}  {4} {1}   {3} {5} {6} {2} | dotarcie do najprostszych problemów
 |     \ /       \ /     \  /
{7}   {1, 4}    {3, 5}  {2, 6} | rozpoczęcie scalania
 \    /            \      /
  {1, 4, 7}      {2, 3, 5, 6}
          \      /
  {1, 2, 3, 4, 5, 5, 6, 7} | posortowana tablica
\end{verbatim}

\newpage
\subsection*{Złożoność obliczeniowa sortowania przez scalanie}

Niech $A$ będzie tablicą o rozmiarze $n$. Algorytm dzieli ją na dwie podtablice
i sortuje je indywidualnie. Każda podtablica odpowiada fragmentowi oryginalnej tablicy, tj.
tablicę $A[p,r]$ dzielimy na $A[p,q]$ i $A[q+1, r]$, gdzie $q = \frac{p+r}{2}$.

Dzielenie każdego $A[p,r]$ na dwie podtablice zajmuje $r-p+1$, a ich ponowne scalenie
również zajmuje $r-p+1$. Zatem dla każdej tablicy, ilość operacji, które algorytm
musi wykonać wynosi dwukrotność jej rozmiaru.

Stąd, jeżeli na danym etapie mamy tablicę rozmiaru $k$, to jej dzielenie i scalanie
zajmie $k+2\cdot\frac{k}{2} = 2k$ operacji.

Spójrzmy na drzewo rekursji, gdzie każdy wierzchołek ma dwójkę dzieci - lewą i prawą stronę.
Każdy wierzchołek oznaczmy rozmiarem tablicy.

\begin{tikzpicture}[level/.style={sibling distance=60mm/#1}]
\node [circle,draw] (z){$n$}
  child {node [circle,draw] (a) {$\frac{n}{2}$}
    child {node [circle,draw] (b) {$\frac{n}{2^2}$}
      child {node {$\vdots$}
        child {node [circle,draw] (d) {$\frac{n}{2^k}$}}
        child {node [circle,draw] (e) {$\frac{n}{2^k}$}}
      }
      child {node {$\vdots$}}
    }
    child {node [circle,draw] (g) {$\frac{n}{2^2}$}
      child {node {$\vdots$}}
      child {node {$\vdots$}}
    }
  }
  child {node [circle,draw] (j) {$\frac{n}{2}$}
    child {node [circle,draw] (k) {$\frac{n}{2^2}$}
      child {node {$\vdots$}}
      child {node {$\vdots$}}
    }
  child {node [circle,draw] (l) {$\frac{n}{2^2}$}
    child {node {$\vdots$}}
    child {node (c){$\vdots$}
      child {node [circle,draw] (o) {$\frac{n}{2^k}$}}
      child {node [circle,draw] (p) {$\frac{n}{2^k}$}
        child [grow=right] {node (q) {$=$} edge from parent[draw=none]
          child [grow=right] {node (q) {$O_{k = \lg n}(n)$} edge from parent[draw=none]
            child [grow=up] {node (r) {$\vdots$} edge from parent[draw=none]
              child [grow=up] {node (s) {$O_2(n)$} edge from parent[draw=none]
                child [grow=up] {node (t) {$O_1(n)$} edge from parent[draw=none]
                  child [grow=up] {node (u) {$O_0(n)$} edge from parent[draw=none]}
                }
              }
            }
            child [grow=down] {node (v) {$O(n \cdot \lg n)$}edge from parent[draw=none]}
          }
        }
      }
    }
  }
};
\path (a) -- (j) node [midway] {+};
\path (b) -- (g) node [midway] {+};
\path (k) -- (l) node [midway] {+};
\path (k) -- (g) node [midway] {+};
\path (d) -- (e) node [midway] {+};
\path (o) -- (p) node [midway] {+};
\path (o) -- (e) node (x) [midway] {$\cdots$}
  child [grow=down] {
    node (y) {$O\left(\displaystyle\sum_{i = 0}^k 2^i \cdot \frac{n}{2^i}\right)$}
    edge from parent[draw=none]
  };
\path (q) -- (r) node [midway] {+};
\path (s) -- (r) node [midway] {+};
\path (s) -- (t) node [midway] {+};
\path (s) -- (l) node [midway] {=};
\path (t) -- (u) node [midway] {+};
\path (z) -- (u) node [midway] {=};
\path (j) -- (t) node [midway] {=};
\path (y) -- (x) node [midway] {$\Downarrow$};
\path (v) -- (y)
  node (w) [midway] {$O\left(\displaystyle\sum_{i = 0}^k n\right) = O(k \cdot n)$};
\path (q) -- (v) node [midway] {=};
\path (e) -- (x) node [midway] {+};
\path (o) -- (x) node [midway] {+};
\path (y) -- (w) node [midway] {$=$};
\path (v) -- (w) node [midway] {$\Leftrightarrow$};
\path (r) -- (c) node [midway] {$\cdots$};
\end{tikzpicture}

\textit{\qquad Kod grafu pochodzi z www.texample.net/tikz/examples/merge-sort-recursion-tree/}

Czas spędzony na każdy z wierzchołków wynosi dwukrotność jego rozmiaru. Zatem
całkowity czas $t$ działania algorytmu można zapisać w postaci:

$$ t = 2\sum_{i=0}^k 2^i \cdot \frac{n}{2^i} = 2\sum_{i=0}^k n $$

Zauważmy, że dla $i=k$, $\frac{n}{2^i} = \frac{n}{2^k}$ wynosi $1$.
Czyli $n = 2^k \implies k = \ceil{\log{n}} $, więc $t$ redukuje się do:
$$ 2\sum_{i=0}^{\ceil{\log{n}}} n = 2n \ceil{\log{n}} $$

Stąd otrzymujemy złożoność obliczeniową algorytmu sortowania przez scalanie:

$$ O(n \log{x}) $$

\end{document}
